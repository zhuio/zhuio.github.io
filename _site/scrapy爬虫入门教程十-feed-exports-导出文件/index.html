<!DOCTYPE html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]--><!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8"><![endif]--><!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9"><![endif]--><!--[if gt IE 8]><!--><html class="no-js">
<!--<![endif]--> <head> <meta charset="UTF-8"> <meta content="text/html; charset=UTF-8" http-equiv="Content-Type"> <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"> <title>Scrapy爬虫入门教程十 Feed exports（导出文件） – 朱智博在Github上的Blog</title> <meta name="description" content="朱智博，朱智博的博客，zhuio,zhuio.github.io,"> <meta name="keywords" content="Scrapy"> <!-- Twitter Cards --> <meta name="twitter:card" content="summary"> <meta name="twitter:image" content="http://localhost:4000/assets/img/logo.png"> <meta name="twitter:title" content="Scrapy爬虫入门教程十 Feed exports（导出文件）"> <meta name="twitter:description" content="Scrapy爬虫入门教程十 Feed exports（导出文件）"> <!-- Open Graph --> <meta property="og:locale" content="zh_CN"> <meta property="og:type" content="article"> <meta property="og:title" content="Scrapy爬虫入门教程十 Feed exports（导出文件）"> <meta property="og:description" content="Scrapy爬虫入门教程十 Feed exports（导出文件）"> <meta property="og:url" content="http://localhost:4000/scrapy%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E5%8D%81-feed-exports-%E5%AF%BC%E5%87%BA%E6%96%87%E4%BB%B6/"> <meta property="og:site_name" content="朱智博在Github上的Blog"> <meta property="og:image" content="http://localhost:4000/assets/img/logo.png"> <link rel="canonical" href="http://localhost:4000/scrapy%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E5%8D%81-feed-exports-%E5%AF%BC%E5%87%BA%E6%96%87%E4%BB%B6/"> <link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="朱智博在Github上的Blog Feed"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- CSS --> <link rel="stylesheet" href="http://localhost:4000/assets/css/main.css"> <!-- JS --> <script src="http://localhost:4000/assets/js/modernizr-3.3.1.custom.min.js"></script> <!-- Favicons --> <link rel="apple-touch-icon" href="http://localhost:4000/assets/img/favicons/apple-icon-precomposed.png"> <link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/assets/img/favicons/apple-icon-72x72.png"> <link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/assets/img/favicons/apple-icon-114x114.png"> <link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/assets/img/favicons/apple-icon-144x144.png"> <link rel="shortcut icon" type="image/png" href="http://localhost:4000/favicon.png"> <link rel="shortcut icon" href="http://localhost:4000/favicon.ico"> <!-- Background Image --> <style type="text/css">body {background-image:url(http://localhost:4000/assets/img/placeholder-big.jpg); background-repeat: no-repeat; background-size: cover; }</style> <!-- Post Feature Image --> </head> <body> <nav id="dl-menu" class="dl-menuwrapper" role="navigation"> <button class="dl-trigger">Open Menu</button> <ul class="dl-menu"> <li><a href="http://localhost:4000/">Home</a></li> <li> <a href="#">About</a> <ul class="dl-submenu"> <li> <img src="http://localhost:4000/assets/img/logo.png" alt="朱智博在Github上的Blog photo" class="author-photo"> <h4>朱智博在Github上的Blog</h4> <p>朱智博，朱智博的博客，zhuio,zhuio.github.io,</p> </li> <li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li> <li> <a href="mailto:185560083@qq.com" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-envelope-square"></i> Email</a> </li> <li> <a href="http://github.com/zhuio" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-github"></i> Github</a> </li> <li> <a href="http://www.weibo.com/EDM_LOVER" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-weibo"></i> Weibo</a> </li> </ul>
<!-- /.dl-submenu --> </li> <li> <a href="#">Posts</a> <ul class="dl-submenu"> <li><a href="http://localhost:4000/posts/">All Posts</a></li> <li><a href="http://localhost:4000/tags/">All Tags</a></li> </ul> </li> <li><a href="http://localhost:4000/projects/">Projects</a></li> </ul>
<!-- /.dl-menu --> </nav><!-- /.dl-menuwrapper --> <!-- Header --> <header class="header" role="banner"> <div class="wrapper animated fadeIn"> <div class="content"> <div class="post-title "> <h1>Scrapy爬虫入门教程十 Feed exports（导出文件）</h1> <h4>09 Apr 2017</h4> <p class="reading-time"> <i class="fa fa-clock-o"></i> Reading time ~1 minute </p>
<!-- /.entry-reading-time --> <a class="btn zoombtn" href="http://localhost:4000/posts/"> <i class="fa fa-chevron-left"></i> </a> </div> <h1 id="scrapy爬虫入门教程十-feed-exports导出文件">Scrapy爬虫入门教程十 Feed exports（导出文件）</h1> <p><strong>开发环境：</strong> <code class="highlighter-rouge">Python 3.6.0 版本</code> （当前最新） <code class="highlighter-rouge">Scrapy 1.3.2 版本</code> （当前最新）</p> <h1 id="导出文件">导出文件</h1> <p>新版本0.10。</p> <p>实现爬虫时最常需要的特征之一是能够正确地存储所过滤的数据，并且经常意味着使用被过滤的数据（通常称为“export feed”）生成要由其他系统消耗的“导出文件” 。</p> <p>Scrapy使用Feed导出功能即时提供此功能，这允许您使用多个序列化格式和存储后端来生成包含已抓取项目的Feed。</p> <h2 id="序列化格式">序列化格式</h2> <p>为了序列化抓取的数据，Feed导出使用项导出器。这些格式是开箱即用的：</p> <ul> <li><a href="http://scrapy.readthedocs.io/en/latest/topics/feed-exports.html#topics-feed-format-json">JSON</a></li> <li><a href="http://scrapy.readthedocs.io/en/latest/topics/feed-exports.html#topics-feed-format-jsonlines">JSON lines</a></li> <li><a href="http://scrapy.readthedocs.io/en/latest/topics/feed-exports.html#topics-feed-format-csv">CSV</a></li> <li><a href="http://scrapy.readthedocs.io/en/latest/topics/feed-exports.html#topics-feed-format-xml">XML</a></li> </ul> <p>但您也可以通过FEED_EXPORTERS设置扩展支持的格式 。</p> <h3 id="json">JSON</h3> <ul> <li>FEED_FORMAT： json</li> <li>使用出口： JsonItemExporter</li> <li>如果您对大型Feed使用JSON，请参阅<a href="http://scrapy.readthedocs.io/en/latest/topics/exporters.html#json-with-large-data">此警告</a>。</li> </ul> <h3 id="json-lines">JSON lines</h3> <ul> <li>FEED_FORMAT： jsonlines</li> <li>使用出口： JsonLinesItemExporter</li> </ul> <h3 id="csv">CSV</h3> <ul> <li>FEED_FORMAT： csv</li> <li>使用出口： CsvItemExporter</li> <li>指定要导出的列及其顺序使用 FEED_EXPORT_FIELDS。其他Feed导出程序也可以使用此选项，但它对CSV很重要，因为与许多其他导出格式不同，CSV使用固定标头。</li> </ul> <h3 id="xml">XML</h3> <ul> <li>FEED_FORMAT： xml</li> <li>使用出口： XmlItemExporter</li> </ul> <h3 id="pickle">Pickle</h3> <ul> <li>FEED_FORMAT： pickle</li> <li>使用出口： PickleItemExporter</li> </ul> <h3 id="marshal">Marshal</h3> <ul> <li>FEED_FORMAT： marshal</li> <li>使用出口： MarshalItemExporter</li> </ul> <hr> <h2 id="存储">存储</h2> <p>使用Feed导出时，您可以使用<a href="https://en.wikipedia.org/wiki/Uniform_Resource_Identifier">URI</a>（通过FEED_URI设置）定义在哪里存储Feed 。Feed导出支持由URI方案定义的多个存储后端类型。</p> <p>支持开箱即用的存储后端包括：</p> <ul> <li><a href="http://scrapy.readthedocs.io/en/latest/topics/feed-exports.html#topics-feed-storage-fs">本地文件系统</a></li> <li><a href="http://scrapy.readthedocs.io/en/latest/topics/feed-exports.html#topics-feed-storage-ftp">FTP</a></li> <li>
<a href="http://scrapy.readthedocs.io/en/latest/topics/feed-exports.html#topics-feed-storage-s3">S3</a>（需要 <a href="https://github.com/boto/botocore">botocore</a>或 <a href="https://github.com/boto/boto">boto</a>）</li> <li><a href="http://scrapy.readthedocs.io/en/latest/topics/feed-exports.html#topics-feed-storage-stdout">标准输出</a></li> </ul> <p>如果所需的外部库不可用，则某些存储后端可能无法使用。例如，S3后端仅在安装了<a href="https://github.com/boto/botocore">botocore</a> 或<a href="https://github.com/boto/boto">boto</a>库时可用（Scrapy仅支持<a href="https://github.com/boto/boto">boto</a>到Python 2）。</p> <hr> <h2 id="存储uri参数">存储URI参数</h2> <p>存储URI还可以包含在创建订阅源时被替换的参数。这些参数是：</p> <ul> <li>%(time)s - 在创建订阅源时由时间戳替换</li> <li>%(name)s - 被蜘蛛名替换</li> </ul> <p>任何其他命名参数将替换为同名的spider属性。例如， 在创建订阅源的那一刻，<code class="highlighter-rouge">%(site_id)s</code>将被<code class="highlighter-rouge">spider.site_id</code>属性替换。</p> <p>这里有一些例子来说明：</p> <ul> <li>存储在FTP中使用每个蜘蛛一个目录：</li> <li> <p><code class="highlighter-rouge">ftp://user:password@ftp.example.com/scraping/feeds/%(name)s/%(time)s.json</code></p> </li> <li>存储在S3使用每个蜘蛛一个目录：</li> <li><code class="highlighter-rouge">s3://mybucket/scraping/feeds/%(name)s/%(time)s.json</code></li> </ul> <h2 id="存储后端">存储后端</h2> <h3 id="本地文件系统">本地文件系统</h3> <p>订阅源存储在本地文件系统中。</p> <p>URI方案： <code class="highlighter-rouge">file</code> 示例URI： <code class="highlighter-rouge">file:///tmp/export.csv</code> 所需的外部库：none <strong>请注意</strong>，（仅）对于本地文件系统存储，如果指定绝对路径，则可以省略该方案<code class="highlighter-rouge">/tmp/export.csv</code>。这只适用于Unix系统。</p> <h3 id="ftp">FTP</h3> <p>订阅源存储在FTP服务器中。</p> <ul> <li>URI方案： <code class="highlighter-rouge">ftp</code>
</li> <li>示例URI： <code class="highlighter-rouge">ftp://user:pass@ftp.example.com/</code>path/to/export.csv</li> <li>所需的外部库：none</li> </ul> <h3 id="s3">S3</h3> <p>订阅源存储在<a href="https://aws.amazon.com/s3/">Amazon S3</a>上。</p> <ul> <li>URI方案： <code class="highlighter-rouge">s3</code>
</li> <li>示例URI：</li> <li><code class="highlighter-rouge">s3://mybucket/path/to/export.csv</code></li> <li> <p><code class="highlighter-rouge">s3://aws_key:aws_secret@mybucket/path/to/export.csv</code></p> </li> <li>所需的外部库：botocore或boto</li> </ul> <p>AWS凭证可以作为URI中的用户/密码传递，也可以通过以下设置传递：</p> <ul> <li><code class="highlighter-rouge">AWS_ACCESS_KEY_ID</code></li> <li><code class="highlighter-rouge">AWS_SECRET_ACCESS_KEY</code></li> </ul> <h3 id="标准输出">标准输出</h3> <p>Feed被写入Scrapy进程的标准输出。</p> <ul> <li>URI方案： <code class="highlighter-rouge">stdout</code>
</li> <li>示例URI： <code class="highlighter-rouge">stdout:</code>
</li> <li>所需的外部库：none</li> </ul> <h2 id="设置">设置</h2> <p>这些是用于配置Feed导出的设置：</p> <ul> <li>FEED_URI （强制性）</li> <li>FEED_FORMAT</li> <li>FEED_STORAGES</li> <li>FEED_EXPORTERS</li> <li>FEED_STORE_EMPTY</li> <li>FEED_EXPORT_ENCODING</li> <li>FEED_EXPORT_FIELDS</li> </ul> <h3 id="feed_uri">FEED_URI</h3> <p>默认： None</p> <p>导出Feed的URI。请参阅支持的URI方案的存储后端。</p> <p>启用Feed导出时需要此设置。</p> <h3 id="feed_format">FEED_FORMAT</h3> <p>要用于Feed的序列化格式。有关可能的值，请参阅 序列化格式。</p> <h3 id="feed_export_encoding">FEED_EXPORT_ENCODING</h3> <p>默认： None</p> <p>要用于Feed的编码。</p> <p>如果取消设置或设置为None（默认），它使用UTF-8除了JSON输出，\uXXXX由于历史原因使用安全的数字编码（序列）。</p> <p>使用utf-8，如果你想UTF-8 JSON了。</p> <h3 id="feed_export_fields">FEED_EXPORT_FIELDS</h3> <p>默认： None</p> <p>要导出的字段的列表，可选。示例：。FEED_EXPORT_FIELDS = [“foo”, “bar”, “baz”]</p> <p>使用FEED_EXPORT_FIELDS选项定义要导出的字段及其顺序。</p> <p>当FEED_EXPORT_FIELDS为空或无（默认）时，Scrapy使用在Item蜘蛛正在产生的dicts 或子类中定义的字段。</p> <p>如果导出器需要一组固定的字段（CSV导出格式为这种情况 ），并且FEED_EXPORT_FIELDS为空或无，则Scrapy会尝试从导出的​​数据中推断字段名称 - 当前它使用第一个项目中的字段名称。</p> <h3 id="feed_store_empty">FEED_STORE_EMPTY</h3> <p>默认： False</p> <p>是否导出空Feed（即，没有项目的Feed）。</p> <p>FEED_STORAGES 默认： {}</p> <p>包含您的项目支持的其他Feed存储后端的字典。键是URI方案，值是存储类的路径。</p> <h3 id="feed_storages_base">FEED_STORAGES_BASE</h3> <p>默认：</p> <div class="highlighter-rouge"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="err">'':</span><span class="w"> </span><span class="err">'scrapy.extensions.feedexport.FileFeedStorage',</span><span class="w">
    </span><span class="err">'file':</span><span class="w"> </span><span class="err">'scrapy.extensions.feedexport.FileFeedStorage',</span><span class="w">
    </span><span class="err">'stdout':</span><span class="w"> </span><span class="err">'scrapy.extensions.feedexport.StdoutFeedStorage',</span><span class="w">
    </span><span class="err">'s3':</span><span class="w"> </span><span class="err">'scrapy.extensions.feedexport.S3FeedStorage',</span><span class="w">
    </span><span class="err">'ftp':</span><span class="w"> </span><span class="err">'scrapy.extensions.feedexport.FTPFeedStorage',</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div> <p>包含Scrapy支持的内置Feed存储后端的字典。您可以通过分配其中None的URI方案 来禁用这些后端FEED_STORAGES。例如，要禁用内置FTP存储后端（无替换），请将其放置在settings.py：</p> <div class="highlighter-rouge"><pre class="highlight"><code>FEED_STORAGES = {
    'ftp': None,
}
</code></pre></div> <h3 id="feed_exporters">FEED_EXPORTERS</h3> <p>默认： {}</p> <p>包含您的项目支持的其他导出器的字典。键是序列化格式，值是Item exporter类的路径。</p> <h3 id="feed_exporters_base">FEED_EXPORTERS_BASE</h3> <p>默认：</p> <div class="highlighter-rouge"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="err">'json':</span><span class="w"> </span><span class="err">'scrapy.exporters.JsonItemExporter',</span><span class="w">
    </span><span class="err">'jsonlines':</span><span class="w"> </span><span class="err">'scrapy.exporters.JsonLinesItemExporter',</span><span class="w">
    </span><span class="err">'jl':</span><span class="w"> </span><span class="err">'scrapy.exporters.JsonLinesItemExporter',</span><span class="w">
    </span><span class="err">'csv':</span><span class="w"> </span><span class="err">'scrapy.exporters.CsvItemExporter',</span><span class="w">
    </span><span class="err">'xml':</span><span class="w"> </span><span class="err">'scrapy.exporters.XmlItemExporter',</span><span class="w">
    </span><span class="err">'marshal':</span><span class="w"> </span><span class="err">'scrapy.exporters.MarshalItemExporter',</span><span class="w">
    </span><span class="err">'pickle':</span><span class="w"> </span><span class="err">'scrapy.exporters.PickleItemExporter',</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div> <p>一个包含Scrapy支持的内置feed导出器的dict。您可以通过分配其中None的序列化格式来禁用任何这些导出器FEED_EXPORTERS。例如，要禁用内置的CSV导出器（无替换），请将其放置在settings.py：</p> <div class="highlighter-rouge"><pre class="highlight"><code>FEED_EXPORTERS = {
    'csv': None,
}
</code></pre></div> <div class="entry-meta"> <br> <hr> <span class="entry-tags"><a href="http://localhost:4000/tags/#Scrapy" title="Pages tagged Scrapy" class="tag"><span class="term">Scrapy</span></a></span> <span class="social-share"> <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/scrapy%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E5%8D%81-feed-exports-%E5%AF%BC%E5%87%BA%E6%96%87%E4%BB%B6/" title="Share on Facebook" class="tag"> <span class="term"><i class="fa fa-facebook-square"></i> Share</span> </a> <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/scrapy%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E5%8D%81-feed-exports-%E5%AF%BC%E5%87%BA%E6%96%87%E4%BB%B6/" title="Share on Twitter" class="tag"> <span class="term"><i class="fa fa-twitter-square"></i> Tweet</span> </a> <a href="https://plus.google.com/share?url=http://localhost:4000/scrapy%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E5%8D%81-feed-exports-%E5%AF%BC%E5%87%BA%E6%96%87%E4%BB%B6/" title="Share on Google+" class="tag"> <span class="term"><i class="fa fa-google-plus-square"></i> +1</span> </a> </span> <div style="clear:both"></div> </div> </div> </div> <h101> <!-- 多说评论框 start --> <div class="ds-thread" data-thread-key="" data-title="Scrapy爬虫入门教程十 Feed exports（导出文件）" data-url="http://localhost:4000"></div> <!-- 多说评论框 end --> <!-- 多说公共JS代码 start (一个网页只需插入一次) --> <script type="text/javascript"> var duoshuoQuery = {short_name:"zhuio"}; (function() { var ds = document.createElement('script'); ds.type = 'text/javascript';ds.async = true; ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js'; ds.charset = 'UTF-8'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds); })(); </script> <!-- 多说公共JS代码 end --> </h101> </header> <!-- JS --> <script src="http://localhost:4000/assets/js/jquery-1.12.0.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.dlmenu.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.goup.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.magnific-popup.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.fitvid.min.js"></script> <script src="http://localhost:4000/assets/js/scripts.js"></script> <script type="text/javascript"> var disqus_shortname = 'zhuio-github-io'; (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })(); (function () { var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = '//' + disqus_shortname + '.disqus.com/count.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); }()); </script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript> <!-- MathJax --> <script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> </body> </html>
